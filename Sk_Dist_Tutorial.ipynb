{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sk-Dist-Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6q9DjAXiCdWg",
        "E1Xg9kvowzF6",
        "TBX18_KOCNUN",
        "5qKKmr0iPxW8",
        "0xGeSTgqPzYM"
      ],
      "mount_file_id": "1ef3CkMTzKcP-mg0CAF9dKfo5B3np6yj6",
      "authorship_tag": "ABX9TyMIJiCq8Oe/v+BEA9XBLXEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prayas99/SkDist-Tutorial/blob/main/Sk_Dist_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q9DjAXiCdWg"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkxGkK-P-TB3"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-CZhSjT18Tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941acd0b-0ca8-4d4c-abd3-f805325a6b13"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 64kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=2737613b823a3c6740c864bdfa4f04bafd2a89cc84a72401d2bdbabc3adc94ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CO0fOP9CWwm",
        "outputId": "eb218c67-8025-43f5-8b2a-6c1af8126655"
      },
      "source": [
        "!pip install sk-dist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sk-dist\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a2/69d38208de981c980eb8513348a82076b26ee52f2066b898d73252b74b95/sk-dist-0.1.9.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 20kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from sk-dist) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->sk-dist) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->sk-dist) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->sk-dist) (1.15.0)\n",
            "Building wheels for collected packages: sk-dist\n",
            "  Building wheel for sk-dist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sk-dist: filename=sk_dist-0.1.9-cp37-none-any.whl size=51838 sha256=cd8f13409ce4a597360947a6f180d1586022227ce3f540f58fc358fca7079a1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/fa/b7/e4c8f3f076a7c907655ea401351658200528b2e73981afb6ea\n",
            "Successfully built sk-dist\n",
            "Installing collected packages: sk-dist\n",
            "Successfully installed sk-dist-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXtg5pwtCKzP"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold  # import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "import json\n",
        "import random\n",
        "import pymongo\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "# from joblibspark import register_spark\n",
        "from joblib import parallel_backend, Parallel, delayed\n",
        "from pprint import pprint\n",
        "import pyspark\n",
        "from itertools import islice\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pickle\n",
        "import time\n",
        "from skdist.distribute.search import DistGridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer, load_boston\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from pyspark.sql import SparkSession\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj-wP9AiKI_N"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, balanced_accuracy_score, average_precision_score, \\\n",
        "    mean_squared_error, r2_score, brier_score_loss\n",
        "from sklearn.utils import resample\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "import random\n",
        "import string\n",
        "import datetime\n",
        "import numpy as np\n",
        "import importlib\n",
        "import sys  \n",
        "import sklearn.cluster as cluster\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from scipy.stats import skew\n",
        "import lightgbm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import plot_importance, to_graphviz\n",
        "from sklearn.metrics import make_scorer, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad as torch_grad\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "rcParams['figure.figsize'] = 9,5\n",
        "randomState = 5\n",
        "np.random.seed(randomState)\n",
        "import pickle\n",
        "from typing import Tuple\n",
        "\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UNraxUxKceE"
      },
      "source": [
        "def build_metrics_df(df1, method, testY, testY_pred, testY_prob):\n",
        "    df = pd.DataFrame(columns = ['Method','Precision','Recall','Bal_Acc','AUPRC', 'AUC-ROC', 'GINI','#1', 'Brier'])\n",
        "    df = df.append({'Method' : str(method),\n",
        "                     'Precision' : precision_score(testY, testY_pred), \n",
        "                    'Recall' : recall_score(testY, testY_pred), \n",
        "                   'Bal_Acc' : balanced_accuracy_score(testY, testY_pred),\n",
        "                    'AUPRC' : average_precision_score(testY,testY_prob), \n",
        "                     'AUC-ROC' : roc_auc_score(testY, testY_prob), \n",
        "                   'GINI' : 2*(roc_auc_score(testY, testY_prob))-1, \n",
        "                    '#1' : testY_pred.sum(),\n",
        "                     'Brier' : (1/brier_score_loss(testY, testY_prob)/10000)}, \n",
        "                ignore_index = True)\n",
        "    frames = [df1, df]\n",
        "    df_merged = pd.concat(frames)\n",
        "    return df_merged\n",
        "df_metrics_empty = pd.DataFrame(columns = ['Method','Precision','Recall','Bal_Acc','AUPRC', 'AUC-ROC', 'GINI','#1' ,'Brier'])\n",
        "\n",
        "def get_cat_dims(X, cat_cols) -> list:\n",
        "    \"\"\"\n",
        "    Takes a pd.DataFrame and a list of columns and returns a list of levels/cardinality per column in the same order.\n",
        "    \"\"\"\n",
        "    return [(X[col].nunique()) for col in cat_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Xg9kvowzF6"
      },
      "source": [
        "# Building train-test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Z0TXWTNSsM"
      },
      "source": [
        "df_orig = pd.read_csv(\"/content/drive/MyDrive/Axis Bank Intern/Kaggle3/hmeq.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Raw3MVEk4sO",
        "outputId": "2ca80e83-5a1d-4100-dcc5-c4ea5f851132"
      },
      "source": [
        "X = df_orig.sample(frac=1, random_state=randomState)\n",
        "Y = X['BAD']\n",
        "del X['BAD']\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5960, 12)\n",
            "(5960,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2F5gflQSySV"
      },
      "source": [
        "cat_cols = ['REASON', 'JOB']\n",
        "num_cols = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG',\n",
        "            'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\n",
        "\n",
        "target_col = 'BAD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlaUmmN_F5vJ",
        "outputId": "f7248f59-cf83-4d2e-cf76-78a661b0ebde"
      },
      "source": [
        "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.1, \\\n",
        "                                                random_state = 5)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "cat_dims = get_cat_dims(trainX, cat_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5364, 12)\n",
            "(596, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohZE9SwIJ0GP",
        "outputId": "5b4dbea1-dc8d-4b13-c8f8-372a6e124747"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "num_prep = make_pipeline(SimpleImputer(strategy='mean'),\n",
        "                         StandardScaler())\n",
        "cat_prep = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
        "                         OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "prep = ColumnTransformer([\n",
        "    ('num', num_prep, num_cols),\n",
        "    ('cat', cat_prep, cat_cols)],\n",
        "    remainder='drop')\n",
        "trainX = prep.fit_transform(trainX)\n",
        "trainX = pd.DataFrame(trainX)\n",
        "testX = prep.transform(testX)\n",
        "testX = pd.DataFrame(testX)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5364, 18)\n",
            "(596, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7z37pqXLbOA"
      },
      "source": [
        "X_res = pd.read_csv('/content/drive/MyDrive/Axis Bank Intern/Kaggle3/X_res_tosave01.csv',index_col=0).values\n",
        "y_res = pd.read_csv('/content/drive/MyDrive/Axis Bank Intern/Kaggle3/y_res_tosave01.csv',index_col=0).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBX18_KOCNUN"
      },
      "source": [
        "# Hyperparameter Tuning using Sk-dist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8bGkD_3pzw"
      },
      "source": [
        "def generate_random_configuration():\n",
        "    params = {'learning_rate': random.uniform(0.01, 0.25),\n",
        "              'colsample_bytree': random.uniform(0.8, 1.0),\n",
        "              'subsample': random.uniform(0.5, 1.0),\n",
        "              'n_estimators': int(math.floor(random.uniform(100, 3000))),\n",
        "              'reg_alpha': random.uniform(0.01, 0.5),\n",
        "              'max_depth': int(math.floor(random.uniform(3, 15))),\n",
        "              'gamma': int(math.floor(random.uniform(0, 10))),\n",
        "              'nthread':1\n",
        "              }\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2WTuH3W6Eut",
        "outputId": "a5d6fae7-48db-4e5b-8ec9-02ff9229f38f"
      },
      "source": [
        "\n",
        "# spark session initialization\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "### XGBClassifier ###\n",
        "\n",
        "# sklearn variables\n",
        "cv = 5\n",
        "clf_scoring = \"roc_auc\"\n",
        "reg_scoring = \"neg_mean_squared_error\"\n",
        "\n",
        "# load sample data (binary target)\n",
        "data = load_breast_cancer()\n",
        "X = X_res\n",
        "y = y_res\n",
        "\n",
        "grid = dict(\n",
        "    learning_rate=[0.05, 0.01],\n",
        "    max_depth=[4, 6, 8],\n",
        "    colsample_bytree=[0.6, 0.8, 1.0],\n",
        "    n_estimators=[100, 200, 300],\n",
        ")\n",
        "start = time.time()\n",
        "### distributed grid search\n",
        "model = DistGridSearchCV(XGBClassifier(), grid, sc, cv=cv, scoring=clf_scoring)\n",
        "# distributed fitting with spark\n",
        "model.fit(X, y)\n",
        "# predictions on the driver\n",
        "preds = model.predict(X)\n",
        "probs = model.predict_proba(X)\n",
        "\n",
        "# results\n",
        "print(\"-- Grid Search --\")\n",
        "print(\"Train time: {0}\".format(time.time() - start))\n",
        "print(\"Best Score: {0}\".format(model.best_score_))\n",
        "print(\"Best colsample_bytree: {0}\".format(model.best_estimator_.colsample_bytree))\n",
        "print(\"Best learning_rate: {0}\".format(model.best_estimator_.learning_rate))\n",
        "print(\"Best max_depth: {0}\".format(model.best_estimator_.max_depth))\n",
        "print(\"Best n_estimators: {0}\".format(model.best_estimator_.n_estimators))\n",
        "print(pickle.loads(pickle.dumps(model)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Grid Search --\n",
            "Train time: 431.4376826286316\n",
            "Best Score: 0.9844365224873773\n",
            "Best colsample_bytree: 0.6\n",
            "Best learning_rate: 0.05\n",
            "Best max_depth: 8\n",
            "Best n_estimators: 200\n",
            "DistGridSearchCV(cv=5, error_score='raise-deprecating',\n",
            "                 estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
            "                                         colsample_bylevel=1,\n",
            "                                         colsample_bynode=1, colsample_bytree=1,\n",
            "                                         gamma=0, learning_rate=0.1,\n",
            "                                         max_delta_step=0, max_depth=3,\n",
            "                                         min_child_weight=1, missing=nan,\n",
            "                                         n_estimators=100, n_jobs=1,\n",
            "                                         nthread=None,\n",
            "                                         objective='binary:logistic',\n",
            "                                         random_state=0, reg_alpha=0,\n",
            "                                         reg_lambda=1, scale_pos_weight=1,\n",
            "                                         seed=None, silent=None, subsample=1,\n",
            "                                         verbosity=1),\n",
            "                 iid='warn', n_jobs=None,\n",
            "                 param_grid={'colsample_bytree': [0.6, 0.8, 1.0],\n",
            "                             'learning_rate': [0.05, 0.01],\n",
            "                             'max_depth': [4, 6, 8],\n",
            "                             'n_estimators': [100, 200, 300]},\n",
            "                 partitions='auto', pre_dispatch='2*n_jobs', preds=False,\n",
            "                 refit=True, return_train_score=False, sc=None,\n",
            "                 scoring='roc_auc', verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qKKmr0iPxW8"
      },
      "source": [
        "# Tuned Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0b9tHsbC3Wm"
      },
      "source": [
        "testY_pred = model.predict(testX.values)\n",
        "testY_prob = model.predict_proba(testX.values)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "IUTiZ9sKMRkg",
        "outputId": "9df6cab3-df3c-4a4a-d7ce-cc2bfbdb6543"
      },
      "source": [
        "# df_metrics_SMOTE_XGB\n",
        "df_metrics_GAN_XGB =build_metrics_df(df_metrics_empty,\\\n",
        "      'GAN_XGB', testY,testY_pred, testY_prob).round(5)  \n",
        "df_metrics_GAN_XGB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Bal_Acc</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>GINI</th>\n",
              "      <th>#1</th>\n",
              "      <th>Brier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GAN_XGB</td>\n",
              "      <td>0.94792</td>\n",
              "      <td>0.79825</td>\n",
              "      <td>0.89394</td>\n",
              "      <td>0.94696</td>\n",
              "      <td>0.97827</td>\n",
              "      <td>0.95654</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.00264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Method  Precision   Recall  Bal_Acc  ...  AUC-ROC     GINI    #1    Brier\n",
              "0  GAN_XGB    0.94792  0.79825  0.89394  ...  0.97827  0.95654  96.0  0.00264\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xGeSTgqPzYM"
      },
      "source": [
        "# Original Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJzBGTsiMSmB"
      },
      "source": [
        "clf = XGBClassifier(max_depth = 3,   \\\n",
        "                n_jobs = 4)\n",
        "probabilities = clf.fit(X_res,y_res).predict_proba(testX.values)\n",
        "testY_prob = probabilities[:, 1]\n",
        "testY_pred = np.where(testY_prob > 0.5, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "5KcNKckQMTyB",
        "outputId": "cf3940b1-4cd0-430d-8d0b-5a2061b81821"
      },
      "source": [
        "# df_metrics_SMOTE_XGB\n",
        "df_metrics_GAN_XGB =build_metrics_df(df_metrics_empty,\\\n",
        "      'GAN_XGB', testY,testY_pred, testY_prob).round(5)  \n",
        "df_metrics_GAN_XGB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Bal_Acc</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>GINI</th>\n",
              "      <th>#1</th>\n",
              "      <th>Brier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GAN_XGB</td>\n",
              "      <td>0.87097</td>\n",
              "      <td>0.71053</td>\n",
              "      <td>0.84282</td>\n",
              "      <td>0.86467</td>\n",
              "      <td>0.94693</td>\n",
              "      <td>0.89386</td>\n",
              "      <td>93</td>\n",
              "      <td>0.00159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Method  Precision   Recall  Bal_Acc    AUPRC  AUC-ROC     GINI  #1    Brier\n",
              "0  GAN_XGB    0.87097  0.71053  0.84282  0.86467  0.94693  0.89386  93  0.00159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY1ijhknuAPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}